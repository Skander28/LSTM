{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxAW0sEB+X6vJzUdQbjfJN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Skander28/Models/blob/main/AraTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    !nvidia-smi\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "iKi6h08xPis3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dlFalZHOPjXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "filtered_df = pd.read_csv('/content/drive/MyDrive/preprocessed_tweets.csv')\n",
        "filtered_df.head()"
      ],
      "metadata": {
        "id": "gK9q8DT7Plum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = filtered_df.dropna()"
      ],
      "metadata": {
        "id": "G1ufvNdaPnbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarabic\n",
        "!pip install optuna==2.3.0\n",
        "!pip install transformers==4.2.1\n",
        "!pip install tokenizers==0.9.4"
      ],
      "metadata": {
        "id": "DyrGsqvQN4Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyarabic.araby as ar\n",
        "\n",
        "import re, functools, operator, string\n",
        "import torch , optuna, gc, random, os  \n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
        "from transformers import Trainer , TrainingArguments\n",
        "from transformers.trainer_utils import EvaluationStrategy\n",
        "from transformers.data.processors.utils import InputFeatures\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.utils import resample\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.WARNING)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "6jAJ4OGINnfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(filtered_df.drop('dialect', axis=1), filtered_df['dialect'])\n",
        "filtered_df = pd.concat([X_resampled, y_resampled], axis=1)"
      ],
      "metadata": {
        "id": "1xUxG16pPaJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Extra_Len = 6 # an extra padding in length , found to be useful for increasing F-score\n",
        "Max_Len = filtered_df[\"tweets\"].str.split().str.len().max() + Extra_Len\n",
        "\n",
        "print(Max_Len)\n",
        "\n",
        "#Spliting the Training data\n",
        "Test_Size = 0.15\n",
        "Rand_Seed = 42 \n",
        "\n",
        "# Split original data into train and test sets\n",
        "train_set, test_set = train_test_split(filtered_df, test_size=Test_Size, random_state=Rand_Seed + 1)\n",
        "\n",
        "# Split training data into train and validation sets\n",
        "train_set, evaluation_set = train_test_split(train_set, test_size=Test_Size, random_state=Rand_Seed)\n",
        "\n",
        "print(\"Train set: \")\n",
        "print(train_set[\"dialect\"].value_counts())\n",
        "print(\"---------------------------\")\n",
        "print (\"Evaluation set: \")\n",
        "print (evaluation_set[\"dialect\"].value_counts())\n",
        "print(\"---------------------------\")\n",
        "print (\"test set: \")\n",
        "print (test_set[\"dialect\"].value_counts())"
      ],
      "metadata": {
        "id": "6RJ58lCFPalK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model_Used= \"aubmindlab/bert-base-arabertv02\"\n",
        "Task_Name = \"classification\"\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(\n",
        "        self,\n",
        "        name,\n",
        "        train,\n",
        "        test,\n",
        "        label_list,\n",
        "    ):\n",
        "        self.name = name\n",
        "        self.train = train\n",
        "        self.test = test\n",
        "        self.label_list = label_list\n",
        "        \n",
        "class BERTModelDataset(Dataset):\n",
        "    def __init__(self, text, target, model_name, max_len, label_map):\n",
        "      super(BERTModelDataset).__init__()\n",
        "      self.text = text\n",
        "      self.target = target\n",
        "      self.tokenizer_name = model_name\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "      self.max_len = max_len\n",
        "      self.label_map = label_map\n",
        "  \n",
        "    def __len__(self):\n",
        "      return len(self.text)\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "      text = str(self.text[item])\n",
        "      text = \" \".join(text.split())\n",
        "    \n",
        "      encoded_review = self.tokenizer.encode_plus(\n",
        "      text,\n",
        "      max_length= self.max_len,\n",
        "      add_special_tokens= True,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      truncation='longest_first',\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt'\n",
        "    )\n",
        "      input_ids = encoded_review['input_ids'].to(device)\n",
        "      attention_mask = encoded_review['attention_mask'].to(device)\n",
        "\n",
        "      return InputFeatures(input_ids=input_ids.flatten(), attention_mask=attention_mask.flatten(), label=self.label_map[self.target[item]])"
      ],
      "metadata": {
        "id": "cZ8Tcu-KNiGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = list(train_set[\"dialect\"].unique())\n",
        "#sentence_list = ['DZ', 'TN', 'MA', 'LY']\n",
        "#ew_label_list = [sentence_list[label] for label in label_list]\n",
        "print(label_list)\n",
        "print(train_set[\"dialect\"].value_counts())\n",
        "\n",
        "data_set = Dataset( \"OLY\", train_set, evaluation_set, label_list )\n",
        "\n",
        "# Define the list of class names\n",
        "#label_list = ['DZ', 'TN', 'MA', 'LY']\n",
        "\n",
        "# Create a label map that maps class names to their corresponding indices\n",
        "label_map = {v: i for i, v in enumerate(label_list)}\n",
        "\n",
        "# Print the label map\n",
        "print(label_map)"
      ],
      "metadata": {
        "id": "7l2hbcQGNzdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_init():\n",
        "  return AutoModelForSequenceClassification.from_pretrained(Model_Used, return_dict=True, num_labels=len(label_map))\n",
        "\n",
        "def compute_metrics(p): #p should be of type EvalPrediction\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  assert len(preds) == len(p.label_ids)\n",
        "  print(classification_report(p.label_ids,preds))\n",
        "  #print(confusion_matrix(p.label_ids,preds))\n",
        "  macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
        "  macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
        "  macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
        "  acc = accuracy_score(p.label_ids,preds)\n",
        "  return {\n",
        "      'macro_f1' : macro_f1, \n",
        "      'macro_precision': macro_precision,\n",
        "      'macro_recall': macro_recall,\n",
        "      'accuracy': acc\n",
        "  }\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "metadata": {
        "id": "D_Ar4TwNNcX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model from a file\n",
        "model_state_dict = torch.load(\"/content/trainer.pth\")"
      ],
      "metadata": {
        "id": "2Qy3EjFg9K8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqsXFRzZ80iS"
      },
      "outputs": [],
      "source": [
        "# Load the trained model\n",
        "model = model_init()\n",
        "\n",
        "# Set the device to use\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Define a single example\n",
        "#example = \"واش دير للعشى\"\n",
        "example = \"شوكران علا هاد \"\n",
        "#example = \"نبي نروح للحوش\"\n",
        "#example = \"شبيك شتحب برا توا\"\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Tokenize the example\n",
        "inputs = tokenizer(example, return_tensors=\"pt\")\n",
        "\n",
        "# Move inputs to the device\n",
        "for k, v in inputs.items():\n",
        "    inputs[k] = v.to(device)\n",
        "\n",
        "# Make a prediction on the single example\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#[0, 3, 2, 1]\n",
        "#{0: 0, 3: 1, 2: 2, 1: 3}\n",
        "#{'DZ': 0, 'LY': 1, 'MA': 2, 'TN': 3}\n",
        "\n",
        "\n",
        "# Define a list of sentences corresponding to each possible class\n",
        "class_sentences = ['DZ Arabic', 'TN Arabic', 'MA Arabic', 'LY Arabic']\n",
        "\n",
        "# Get the predicted class\n",
        "predicted_class = torch.argmax(outputs.logits).item()\n",
        "\n",
        "# Get the corresponding sentence\n",
        "predicted_sentence = class_sentences[predicted_class]\n",
        "\n",
        "# Print the predicted sentence\n",
        "print(\"Predicted sentence for the single example:\", predicted_sentence)"
      ]
    }
  ]
}