{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXCYqstdF+Yl9cMxOulTgu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Skander28/Models/blob/main/Test(CNN_bi_SA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "3k9OJpd8YhKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnLR4vWlYh3m",
        "outputId": "ccd31b37-1d1c-4056-fe93-d7d1d3ce6a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "filtered_df = pd.read_csv('/content/drive/MyDrive/preprocessed_tweets.csv')\n",
        "filtered_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "w1wJobuUYkXu",
        "outputId": "11ea280f-73d7-433b-d4ba-3f0f22babea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                   id  dialect  \\\n",
              "0       15497  1009754958479151232        1   \n",
              "1       15498  1009794751548313600        1   \n",
              "2       15499  1019989115490787200        1   \n",
              "3       15500  1035479791758135168        1   \n",
              "4       15501  1035481122921164800        1   \n",
              "\n",
              "                                              tweets  \n",
              "0  قليلين ادب ومنافقين اختهم او قريبتهم تعاكس تقو...  \n",
              "1  اليبين متقلبين بالنسبه ليا انا ميليشياوي زمان ...  \n",
              "2  تانيه شاب ليبي بيرتاح لبنت مختلفه ويلاحظ انها ...  \n",
              "3  رانيا عقليتك متخلفه اولا الانسان يلي يحتاج اهل...  \n",
              "4  شكلك متعقده علشان الراجل تحبيه ازوج بنت يتيمه ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6a67e9d-a872-4bc9-adb7-5af7ae512f30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>dialect</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15497</td>\n",
              "      <td>1009754958479151232</td>\n",
              "      <td>1</td>\n",
              "      <td>قليلين ادب ومنافقين اختهم او قريبتهم تعاكس تقو...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15498</td>\n",
              "      <td>1009794751548313600</td>\n",
              "      <td>1</td>\n",
              "      <td>اليبين متقلبين بالنسبه ليا انا ميليشياوي زمان ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15499</td>\n",
              "      <td>1019989115490787200</td>\n",
              "      <td>1</td>\n",
              "      <td>تانيه شاب ليبي بيرتاح لبنت مختلفه ويلاحظ انها ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15500</td>\n",
              "      <td>1035479791758135168</td>\n",
              "      <td>1</td>\n",
              "      <td>رانيا عقليتك متخلفه اولا الانسان يلي يحتاج اهل...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15501</td>\n",
              "      <td>1035481122921164800</td>\n",
              "      <td>1</td>\n",
              "      <td>شكلك متعقده علشان الراجل تحبيه ازوج بنت يتيمه ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6a67e9d-a872-4bc9-adb7-5af7ae512f30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6a67e9d-a872-4bc9-adb7-5af7ae512f30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6a67e9d-a872-4bc9-adb7-5af7ae512f30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.dialect.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7vI2Ezco1gJ",
        "outputId": "7d01c862-5539-4540-bc0f-ac33a8bde3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    36499\n",
              "0    16183\n",
              "2    11539\n",
              "3     9246\n",
              "Name: dialect, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = filtered_df.dropna()"
      ],
      "metadata": {
        "id": "tg1pfhhDYnCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "features = filtered_df.tweets.values\n",
        "labels = pd.get_dummies(filtered_df['dialect']).values"
      ],
      "metadata": {
        "id": "PbpL3y1yYqJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 20000\n",
        "max_length= 200\n",
        "tokenizer = Tokenizer(num_words=vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=False)\n",
        "tokenizer.fit_on_texts(features)\n",
        "X = tokenizer.texts_to_sequences(features)"
      ],
      "metadata": {
        "id": "SMIOqmcNYsP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from collections import Counter\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# use the stopwords\n",
        "stop_words = set(stopwords.words('arabic'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JPvl_QaYujc",
        "outputId": "673eecdd-6b69-47c7-bc42-5d13df45440f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = []\n",
        "for tokens in X:\n",
        "    all_words.extend(tokens)\n",
        "\n",
        "stop_words = set(stopwords.words('arabic'))\n",
        "all_words = [word for word in all_words if word not in stop_words]\n",
        "\n",
        "word_counts = Counter(all_words)\n",
        "most_common_words = [word for word, count in word_counts.most_common(500)]\n",
        "\n",
        "def remove_common_words(tokens):\n",
        "  new_tokens = [token for token in tokens if token not in most_common_words]\n",
        "  return new_tokens\n",
        "\n",
        "X = remove_common_words(X)\n",
        "\n",
        "\n",
        "X = pad_sequences(X, maxlen=max_length)"
      ],
      "metadata": {
        "id": "HkvxNj16Yw73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.1, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "1hLnNJBbYzAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_test, y_test = torch.tensor(X_test), torch.tensor(y_test)"
      ],
      "metadata": {
        "id": "GTLrO_5YY2oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "vocab_size = 20000\n",
        "embedding_dim = 100\n",
        "hidden_dim = 128\n",
        "output_dim = 4\n",
        "num_layers = 2\n",
        "bidirectional = True\n",
        "lr = 0.01\n",
        "batch_size = 64\n",
        "num_epochs = 100\n",
        "patience = 5\n",
        "\n",
        "class BiLSTMAttention(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(BiLSTMAttention, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, embedding_dim), padding=(1, 0))\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 1), padding=(1, 0))\n",
        "        self.lstm = nn.LSTM(200, hidden_dim, num_layers=num_layers, bidirectional=True, dropout=0.5, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.attention = SelfAttention(hidden_dim * 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        conv1_out = F.relu(self.conv1(embedded.unsqueeze(1)))\n",
        "        conv2_out = F.relu(self.conv2(conv1_out))\n",
        "        conv2_out = conv2_out.permute(0, 2, 1, 3)\n",
        "        conv2_out = conv2_out.reshape(conv2_out.size(0), conv2_out.size(1), -1)\n",
        "        lstm_in = conv2_out.permute(0, 2, 1)\n",
        "        lstm_out, _ = self.lstm(lstm_in)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        attention_out , attention_weights= self.attention(lstm_out)\n",
        "        fc_out = self.fc(attention_out)\n",
        "        return fc_out, attention_weights\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "        )\n",
        "        \n",
        "    def forward(self, encoder_outputs):\n",
        "        energy = self.projection(encoder_outputs)\n",
        "        weights = F.softmax(energy.flatten(start_dim=1), dim=1)\n",
        "        outputs = (encoder_outputs * weights.unsqueeze(-1)).sum(dim=1)\n",
        "        return outputs, weights"
      ],
      "metadata": {
        "id": "HZq6JzvucuDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6Xj5JlPDOCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d52ffe-7826-4602-8b17-1fbbde47f449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-0.9055, -1.0567, -1.1945, -1.1836],\n",
            "        [-0.9055, -1.0567, -1.1945, -1.1836],\n",
            "        [-0.9055, -1.0567, -1.1945, -1.1836],\n",
            "        ...,\n",
            "        [-0.9055, -1.0567, -1.1945, -1.1836],\n",
            "        [-0.9055, -1.0567, -1.1945, -1.1836],\n",
            "        [-0.9055, -1.0567, -1.1945, -1.1836]]), tensor([[1.9252e-03, 6.8995e-03, 2.5312e-02,  ..., 2.6256e-02, 9.3752e-05,\n",
            "         2.5925e-21],\n",
            "        [1.9252e-03, 6.8995e-03, 2.5312e-02,  ..., 2.6256e-02, 9.3752e-05,\n",
            "         2.5925e-21],\n",
            "        [1.9252e-03, 6.8995e-03, 2.5312e-02,  ..., 2.6256e-02, 9.3752e-05,\n",
            "         2.5925e-21],\n",
            "        ...,\n",
            "        [1.9252e-03, 6.8995e-03, 2.5312e-02,  ..., 2.6256e-02, 9.3752e-05,\n",
            "         2.5925e-21],\n",
            "        [1.9252e-03, 6.8995e-03, 2.5312e-02,  ..., 2.6256e-02, 9.3752e-05,\n",
            "         2.5925e-21],\n",
            "        [1.9252e-03, 6.8995e-03, 2.5312e-02,  ..., 2.6256e-02, 9.3752e-05,\n",
            "         2.5925e-21]]))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "model = BiLSTMAttention(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers)\n",
        "model.load_state_dict(torch.load(\"/content/model2.pth\", map_location=torch.device('cpu')))\n",
        "# model.to(\"cuda:0\")\n",
        "model.eval()\n",
        "X_test = X_test\n",
        "# Compute the model's prediction for the padded sequence\n",
        "with torch.no_grad():\n",
        "    pred_ = model(X_test)\n",
        "    print(pred_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsVRf10Mk7f8",
        "outputId": "fd0461cf-096d-44d2-f4e3-4433e5f7ff00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7344, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pred_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Oqn3zATf3wZ",
        "outputId": "f0ea7e55-bdb5-417a-c71b-27e565e0d13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(pred_[0].cpu().numpy(), axis=1)"
      ],
      "metadata": {
        "id": "wyTCeKRMgBO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(a, num_classes):\n",
        "   a = np.array(a) \n",
        "   return np.squeeze(np.eye(num_classes)[a.reshape(-1)])\n",
        "preds = one_hot(preds,4)"
      ],
      "metadata": {
        "id": "p_i5Wkw5gGo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds\n",
        "pred_results_np = np.array(preds)\n",
        "x_np = torch.from_numpy(pred_results_np)"
      ],
      "metadata": {
        "id": "ZqNM5_PUgJha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozs9ZBF3kegr",
        "outputId": "6a810ca9-a6f2-402d-b51b-1ed53121e77e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7344"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVu7y7OckeVI",
        "outputId": "1bedb322-4f7a-4f4b-dfb8-12c4504529a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7344, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "recall_score(y_test, x_np,average='macro') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L_bYOlXgOy1",
        "outputId": "8200a5b3-4fa4-4a2b-d66f-15a330a24159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_score(y_test, x_np,average='macro') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIvVzAwygRK9",
        "outputId": "0266536f-9ada-4f1a-ed3f-7c39a24291af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0542619825708061"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, pred_results_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBz2M0c8gTmy",
        "outputId": "9bd83f45-b3b6-4f16-f042-a5a60e8fcffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2170479302832244"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_test, x_np,average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QakDgwyFgVsy",
        "outputId": "15c56698-79b0-40bd-9ecd-9dfe7ce86c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08916983665249496"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "device = \"cuda\"\n",
        "# Tokenize the new complaint and pad the sequence\n",
        "new_complaint = ['واش دير للعشى']\n",
        "seq = tokenizer.texts_to_sequences(new_complaint)\n",
        "padded = pad_sequences(seq, maxlen=max_length)\n",
        "\n",
        "# Convert the padded sequence to a PyTorch tensor and move it to the device (e.g., GPU) if available\n",
        "padded_tensor = torch.LongTensor(padded)\n",
        "\n",
        "# Compute the model's prediction for the padded sequence\n",
        "with torch.no_grad():\n",
        "    pred = model(padded_tensor)\n",
        "\n",
        "# Move the prediction back to the CPU and convert to a numpy array\n",
        "#pred = pred.cpu().numpy()\n",
        "\n",
        "# Map the prediction to a class label using the CLASS_DICT{'DZ': 0, 'LY': 1, 'MA': 2, 'TN': 3}\n",
        "CLASS_DICT = {0: \"DZ\",1: \"LY\", 2: \"MA\",3: \"TN\"}\n",
        "class_label = CLASS_DICT[np.argmax(pred[0].cpu().numpy(), axis=1)[0]]\n",
        "\n",
        "# Print the prediction and the predicted class label\n",
        "print(class_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul-kjU9YgesO",
        "outputId": "1dec9a43-2b7d-4122-f9a9-75e1d63c3ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DZ\n"
          ]
        }
      ]
    }
  ]
}