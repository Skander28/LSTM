{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b6eb5ebcc34414babd2c8905c735f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db1816c272b94b2ba3045f1cbf2e0230",
              "IPY_MODEL_661d704e821749e8a8e76e198c1025d7",
              "IPY_MODEL_02fc41b866d84d9a9763a1e862593f85"
            ],
            "layout": "IPY_MODEL_26a406b85e7f47cd8bef54d9a0bc0358"
          }
        },
        "db1816c272b94b2ba3045f1cbf2e0230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_782126d6186b4e3e8f21d97ffcbbdb1e",
            "placeholder": "​",
            "style": "IPY_MODEL_2e6d3d1b7ac6454499d66245ca731556",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "661d704e821749e8a8e76e198c1025d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62fe3ff0bef6477f9ba6eeac5a633a2f",
            "max": 376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47e8349d2a384f9c964c830226e4c3fd",
            "value": 376
          }
        },
        "02fc41b866d84d9a9763a1e862593f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecb25c907b444387ab5626092ce6a12f",
            "placeholder": "​",
            "style": "IPY_MODEL_1069e6fc1b0c4626926cfdb27dbc597a",
            "value": " 376/376 [00:00&lt;00:00, 9.08kB/s]"
          }
        },
        "26a406b85e7f47cd8bef54d9a0bc0358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "782126d6186b4e3e8f21d97ffcbbdb1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e6d3d1b7ac6454499d66245ca731556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62fe3ff0bef6477f9ba6eeac5a633a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47e8349d2a384f9c964c830226e4c3fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecb25c907b444387ab5626092ce6a12f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1069e6fc1b0c4626926cfdb27dbc597a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f74f071d3d841709b48efe7d1842b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7a1f0f889df45138a64e647f37d1558",
              "IPY_MODEL_e828b8ebb1cd4416b8fb81c6fc0aec19",
              "IPY_MODEL_4e2b368e64304e6fa69fa093682d151e"
            ],
            "layout": "IPY_MODEL_efb3d70abd75491a9104373a6651a678"
          }
        },
        "c7a1f0f889df45138a64e647f37d1558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_403208fa4a2f49d48bb717184a560a3d",
            "placeholder": "​",
            "style": "IPY_MODEL_f75b2620a51042e7917fcdd325f84588",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "e828b8ebb1cd4416b8fb81c6fc0aec19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9db1e69b5ae4c179d7e46848c65703d",
            "max": 1099714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f8794faf02a47ceba924769bdd4c556",
            "value": 1099714
          }
        },
        "4e2b368e64304e6fa69fa093682d151e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_092abab84d844a82b163ad06626c4a9b",
            "placeholder": "​",
            "style": "IPY_MODEL_83cd5eedab8b44e3adbcb7ae11ec10f2",
            "value": " 1.10M/1.10M [00:00&lt;00:00, 19.0MB/s]"
          }
        },
        "efb3d70abd75491a9104373a6651a678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "403208fa4a2f49d48bb717184a560a3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f75b2620a51042e7917fcdd325f84588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9db1e69b5ae4c179d7e46848c65703d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f8794faf02a47ceba924769bdd4c556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "092abab84d844a82b163ad06626c4a9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83cd5eedab8b44e3adbcb7ae11ec10f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba2c453d26ba4b098a740466cbaa652a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_819a61d8e23442f38ba3e13471c2cc53",
              "IPY_MODEL_6c93b984e92b4382a9abe412c5bf504b",
              "IPY_MODEL_9277deb1a66540ee8475e0f728eac2a0"
            ],
            "layout": "IPY_MODEL_4c3c5011ca8b4694a49dfa2488eff746"
          }
        },
        "819a61d8e23442f38ba3e13471c2cc53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c3fa7cab0c541679fe6b889ddf53818",
            "placeholder": "​",
            "style": "IPY_MODEL_ed434f88b2c9478daa137776d0f0b7d8",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "6c93b984e92b4382a9abe412c5bf504b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e84d37290dd4a78afc8d094e48ebefb",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25d77f65bc7741f5b51be81fe71b4e2c",
            "value": 112
          }
        },
        "9277deb1a66540ee8475e0f728eac2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eab5113af43b4125b2b4f25088e336e3",
            "placeholder": "​",
            "style": "IPY_MODEL_0093b37ea08f45c5a3a9c500d7e9cd7b",
            "value": " 112/112 [00:00&lt;00:00, 4.73kB/s]"
          }
        },
        "4c3c5011ca8b4694a49dfa2488eff746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c3fa7cab0c541679fe6b889ddf53818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed434f88b2c9478daa137776d0f0b7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e84d37290dd4a78afc8d094e48ebefb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d77f65bc7741f5b51be81fe71b4e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eab5113af43b4125b2b4f25088e336e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0093b37ea08f45c5a3a9c500d7e9cd7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Skander28/Models/blob/main/Marbert(newdata).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u75gG2LO7v2D",
        "outputId": "48d11437-cf61-4a3a-c43c-e7aac26a0440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Wed May 10 10:13:09 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8    10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.  \n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    !nvidia-smi\n",
        "    \n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install needed libraries\n",
        "!pip install pyarabic\n",
        "!pip install emoji\n",
        "!pip install pystemmer\n",
        "!pip install optuna==2.3.0\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THjZAXR87x8b",
        "outputId": "24bd860b-27a0-4f94-af15-1664ab6d6774"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyarabic\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from pyarabic) (1.16.0)\n",
            "Installing collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234911 sha256=a2130ae8192fc01c637acf777667b7e6619ab94eff784c1ba36deb1b19acbe6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/3d/88/51a592b9ad17e7899126563698b4e3961983ebe85747228ba6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pystemmer\n",
            "  Downloading PyStemmer-2.2.0.1.tar.gz (303 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.0/303.0 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pystemmer\n",
            "  Building wheel for pystemmer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pystemmer: filename=PyStemmer-2.2.0.1-cp310-cp310-linux_x86_64.whl size=584843 sha256=dc46f065adb93df706d2e8847ed9075093632cbda3644d6e1c6f0d4a10fee1e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/7d/2c/a7ebb8319e01acc5306fa1f8558bf24063d6cec2c02de330c9\n",
            "Successfully built pystemmer\n",
            "Installing collected packages: pystemmer\n",
            "Successfully installed pystemmer-2.2.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna==2.3.0\n",
            "  Downloading optuna-2.3.0.tar.gz (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.6/258.6 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting alembic (from optuna==2.3.0)\n",
            "  Downloading alembic-1.10.4-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cliff (from optuna==2.3.0)\n",
            "  Downloading cliff-4.3.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.6.0 (from optuna==2.3.0)\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog (from optuna==2.3.0)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from optuna==2.3.0) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna==2.3.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna==2.3.0) (23.1)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.10/dist-packages (from optuna==2.3.0) (1.10.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from optuna==2.3.0) (2.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna==2.3.0) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.1.0->optuna==2.3.0) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.1.0->optuna==2.3.0) (2.0.2)\n",
            "Collecting Mako (from alembic->optuna==2.3.0)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from cliff->optuna==2.3.0) (0.7.2)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.10/dist-packages (from cliff->optuna==2.3.0) (6.0)\n",
            "Collecting autopage>=0.4.0 (from cliff->optuna==2.3.0)\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting cmd2>=1.0.0 (from cliff->optuna==2.3.0)\n",
            "  Downloading cmd2-2.4.3-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.2/147.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata>=4.4 (from cliff->optuna==2.3.0)\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Collecting stevedore>=2.0.1 (from cliff->optuna==2.3.0)\n",
            "  Downloading stevedore-5.0.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.10/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.3.0) (23.1.0)\n",
            "Collecting pyperclip>=1.6 (from cmd2>=1.0.0->cliff->optuna==2.3.0)\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.3.0) (0.2.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.4->cliff->optuna==2.3.0) (3.15.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0 (from stevedore>=2.0.1->cliff->optuna==2.3.0)\n",
            "  Downloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic->optuna==2.3.0) (2.1.2)\n",
            "Building wheels for collected packages: optuna, pyperclip\n",
            "  Building wheel for optuna (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.3.0-py3-none-any.whl size=359702 sha256=198d872cf7f9a8bb910e8a67e973c0642d3e42c6a01f5718e3df9dd3919b7aa1\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/21/72/0aa4c862f07f82e9a7ce17b431f7da08395f0232b4b749f289\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11124 sha256=734476ec641d4cb39fe91747c9af4e976728fd8784d455c9489a5dc25b10b5bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/24/fe/140a94a7f1036003ede94579e6b4227fe96c840c6f4dcbe307\n",
            "Successfully built optuna pyperclip\n",
            "Installing collected packages: pyperclip, pbr, Mako, importlib-metadata, colorlog, cmd2, cmaes, autopage, stevedore, alembic, cliff, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.4 autopage-0.5.1 cliff-4.3.0 cmaes-0.9.1 cmd2-2.4.3 colorlog-6.7.0 importlib-metadata-6.6.0 optuna-2.3.0 pbr-5.11.1 pyperclip-1.8.2 stevedore-5.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import needed libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyarabic.araby as ar\n",
        "\n",
        "import re , emoji, Stemmer, functools, operator, string\n",
        "import torch , optuna, gc, random, os\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer\n",
        "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
        "from transformers import Trainer , TrainingArguments\n",
        "from transformers.trainer_utils import EvaluationStrategy\n",
        "from transformers.data.processors.utils import InputFeatures\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.utils import resample\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.WARNING)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "lZ7r62fP70T3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "     \n",
        "import pandas as pd\n",
        "tweets = pd.read_csv('/content/drive/MyDrive/NEWData.csv')\n",
        "tweets.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "VlKrNE8G8HlY",
        "outputId": "bfc6f545-68c8-4122-d600-e1b155c7ab56"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                   id  \\\n",
              "0           0  1002651298255261568   \n",
              "1           1  1031909335482417152   \n",
              "2           2  1031910848443437056   \n",
              "3           3  1033650943387156352   \n",
              "4           4  1038485382818656384   \n",
              "\n",
              "                                                text  word_count  char_count  \\\n",
              "0              @Sharehanart يمه الزين 😍 ربي يحفظك 😘😘         7.0        37.0   \n",
              "1  @azeezAzmm وأنت بألف خير عيني.. ينعاد عليكم با...        12.0        67.0   \n",
              "2  @Mohmadridi6 امين يارب\\nوصحا عيدك كل عام وانت ...         9.0        53.0   \n",
              "3  @saraup01 بصحتك وربي يجيب شفاا وانتي علاه تكثر...        10.0        57.0   \n",
              "4         ماعاد نجامل أحد خلي الناس تعرف انها خرا 💩💩         9.0        42.0   \n",
              "\n",
              "   avg_char_per_word  stopwords  emoji_count  \\\n",
              "0           4.428571        0.0          3.0   \n",
              "1           4.666667        1.0          2.0   \n",
              "2           4.400000        1.0          3.0   \n",
              "3           4.800000        0.0          5.0   \n",
              "4           3.777778        1.0          2.0   \n",
              "\n",
              "                                          clean_text dialect  \n",
              "0                                يمه الزين ربي يحفظك      DZ  \n",
              "1  وانت بالف خير عيني ينعاد عليكم بالصحه والعافيه...      DZ  \n",
              "2               امين يارب وصحا عيدك كل عام وانت بخير      DZ  \n",
              "3          بصحتك وربي يجيب شفاا وانتي علاه تكثري منو      DZ  \n",
              "4            ماعاد نجامل احد خلي الناس تعرف انها خرا      DZ  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d506dcf1-c99c-45b4-a9a3-f88207856e89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>word_count</th>\n",
              "      <th>char_count</th>\n",
              "      <th>avg_char_per_word</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>emoji_count</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>dialect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1002651298255261568</td>\n",
              "      <td>@Sharehanart يمه الزين 😍 ربي يحفظك 😘😘</td>\n",
              "      <td>7.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>يمه الزين ربي يحفظك</td>\n",
              "      <td>DZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1031909335482417152</td>\n",
              "      <td>@azeezAzmm وأنت بألف خير عيني.. ينعاد عليكم با...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>وانت بالف خير عيني ينعاد عليكم بالصحه والعافيه...</td>\n",
              "      <td>DZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1031910848443437056</td>\n",
              "      <td>@Mohmadridi6 امين يارب\\nوصحا عيدك كل عام وانت ...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>امين يارب وصحا عيدك كل عام وانت بخير</td>\n",
              "      <td>DZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1033650943387156352</td>\n",
              "      <td>@saraup01 بصحتك وربي يجيب شفاا وانتي علاه تكثر...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>4.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>بصحتك وربي يجيب شفاا وانتي علاه تكثري منو</td>\n",
              "      <td>DZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1038485382818656384</td>\n",
              "      <td>ماعاد نجامل أحد خلي الناس تعرف انها خرا 💩💩</td>\n",
              "      <td>9.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>3.777778</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>ماعاد نجامل احد خلي الناس تعرف انها خرا</td>\n",
              "      <td>DZ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d506dcf1-c99c-45b4-a9a3-f88207856e89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d506dcf1-c99c-45b4-a9a3-f88207856e89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d506dcf1-c99c-45b4-a9a3-f88207856e89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_cleaning (text):\n",
        "  try:\n",
        "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'^http?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"https\\S+\", \"\", text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(\"(\\s\\d+)\",\"\",text) \n",
        "    text = re.sub(r\"$\\d+\\W+|\\b\\d+\\b|\\W+\\d+$\", \"\", text)\n",
        "    text = re.sub(\"\\d+\", \" \", text)\n",
        "    text = text.replace(\"#\", \" \");\n",
        "    text = text.replace(\"@\", \" \");\n",
        "    text = text.replace(\"_\", \" \");\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "  except:\n",
        "    return text\n",
        "   \n",
        "  return text"
      ],
      "metadata": {
        "id": "kNETAp3U8isa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning Training Data \n",
        "tweets['text'] = tweets['text'].apply(lambda x:   data_cleaning(x))"
      ],
      "metadata": {
        "id": "LFnK6yhJCgAu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a class representing the dataset\n",
        "class Dataset:\n",
        "    def __init__(\n",
        "        self,\n",
        "        name,\n",
        "        train,\n",
        "        test,\n",
        "        label_list,\n",
        "    ):\n",
        "        self.name = name\n",
        "        self.train = train\n",
        "        self.test = test\n",
        "        self.label_list = label_list"
      ],
      "metadata": {
        "id": "zpZvz79M8ORr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTModelDataset(Dataset):\n",
        "    def __init__(self, text, target, model_name, max_len, label_map):\n",
        "      super(BERTModelDataset).__init__()\n",
        "      self.text = text\n",
        "      self.target = target\n",
        "      self.tokenizer_name = model_name\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "      self.max_len = max_len\n",
        "      self.label_map = label_map\n",
        "  \n",
        "    def __len__(self):\n",
        "      return len(self.text)\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "      text = str(self.text[item])\n",
        "      text = \" \".join(text.split())\n",
        "    \n",
        "      encoded_review = self.tokenizer.encode_plus(\n",
        "      text,\n",
        "      max_length= self.max_len,\n",
        "      add_special_tokens= True,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      truncation='longest_first',\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt'\n",
        "    )\n",
        "      input_ids = encoded_review['input_ids'].to(device)\n",
        "      attention_mask = encoded_review['attention_mask'].to(device)\n",
        "\n",
        "      return InputFeatures(input_ids=input_ids.flatten(), attention_mask=attention_mask.flatten(), label=self.label_map[self.target[item]])"
      ],
      "metadata": {
        "id": "jb1_YeZ08T4D"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Extra_Len = 6 # an extra padding in length , found to be useful for increasing F-score\n",
        "Max_Len = tweets[\"text\"].str.split().str.len().max() + Extra_Len\n",
        "\n",
        "print(Max_Len)\n",
        "\n",
        "#Spliting the Training data\n",
        "Test_Size = 0.15\n",
        "Rand_Seed = 42 \n",
        "\n",
        "# Split original data into train and test sets\n",
        "train_set, test_set = train_test_split(tweets, test_size=Test_Size, random_state=Rand_Seed + 1)\n",
        "\n",
        "# Split training data into train and validation sets\n",
        "train_set, evaluation_set = train_test_split(train_set, test_size=Test_Size, random_state=Rand_Seed)\n",
        "\n",
        "print(\"Train set: \")\n",
        "print(train_set[\"dialect\"].value_counts())\n",
        "print(\"---------------------------\")\n",
        "print (\"Evaluation set: \")\n",
        "print (evaluation_set[\"dialect\"].value_counts())\n",
        "print(\"---------------------------\")\n",
        "print (\"test set: \")\n",
        "print (test_set[\"dialect\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7mvw8_aCRVw",
        "outputId": "2de53f87-c7ba-4e31-a740-441ef0b0e6f2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94\n",
            "Train set: \n",
            "TN    11738\n",
            "MA    11683\n",
            "LY    11649\n",
            "DZ    11629\n",
            "Name: dialect, dtype: int64\n",
            "---------------------------\n",
            "Evaluation set: \n",
            "MA    2088\n",
            "LY    2072\n",
            "DZ    2042\n",
            "TN    2039\n",
            "Name: dialect, dtype: int64\n",
            "---------------------------\n",
            "test set: \n",
            "DZ    2488\n",
            "LY    2438\n",
            "MA    2388\n",
            "TN    2382\n",
            "Name: dialect, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_Used = \"UBC-NLP/MARBERT\"\n",
        "Task_Name = \"classification\"\n",
        "\n",
        "def model_init():\n",
        "  return AutoModelForSequenceClassification.from_pretrained(Model_Used, return_dict=True, num_labels=len(label_map))\n",
        "\n",
        "def compute_metrics(p): #p should be of type EvalPrediction\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  assert len(preds) == len(p.label_ids)\n",
        "  print(classification_report(p.label_ids,preds))\n",
        "  #print(confusion_matrix(p.label_ids,preds))\n",
        "\n",
        "  macro_f1_pos_neg = f1_score(p.label_ids,preds,average='macro',labels=[1,2])\n",
        "  macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
        "  macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
        "  macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
        "  acc = accuracy_score(p.label_ids,preds)\n",
        "  return {\n",
        "      'macro_f1' : macro_f1,\n",
        "      'macro_f1_pos_neg' : macro_f1_pos_neg,  \n",
        "      'macro_precision': macro_precision,\n",
        "      'macro_recall': macro_recall,\n",
        "      'accuracy': acc\n",
        "  }\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "metadata": {
        "id": "E7Ehj5b48l4i"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = list(train_set[\"dialect\"].unique())\n",
        "#sentence_list = ['DZ', 'TN', 'MA', 'LY']\n",
        "#ew_label_list = [sentence_list[label] for label in label_list]\n",
        "print(label_list)\n",
        "print(train_set[\"dialect\"].value_counts())\n",
        "\n",
        "data_set = Dataset( \"OLY\", train_set, evaluation_set, label_list )\n",
        "\n",
        "# Define the list of class names\n",
        "#label_list = ['DZ', 'TN', 'MA', 'LY']\n",
        "\n",
        "# Create a label map that maps class names to their corresponding indices\n",
        "label_map = {v: i for i, v in enumerate(label_list)}\n",
        "\n",
        "# Print the label map\n",
        "print(label_map)\n",
        "\n",
        "train_dataset = BERTModelDataset(train_set[\"text\"].to_list(),\n",
        "                                 train_set[\"dialect\"].to_list(),Model_Used,int(Max_Len),label_map)\n",
        "\n",
        "evaluation_dataset = BERTModelDataset(evaluation_set[\"text\"].to_list(),\n",
        "                                      evaluation_set[\"dialect\"].to_list(),Model_Used,int(Max_Len),label_map)\n",
        "\n",
        "test_dataset = BERTModelDataset(test_set[\"text\"].to_list(),\n",
        "                                      test_set[\"dialect\"].to_list(),Model_Used,int(Max_Len),label_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235,
          "referenced_widgets": [
            "9b6eb5ebcc34414babd2c8905c735f37",
            "db1816c272b94b2ba3045f1cbf2e0230",
            "661d704e821749e8a8e76e198c1025d7",
            "02fc41b866d84d9a9763a1e862593f85",
            "26a406b85e7f47cd8bef54d9a0bc0358",
            "782126d6186b4e3e8f21d97ffcbbdb1e",
            "2e6d3d1b7ac6454499d66245ca731556",
            "62fe3ff0bef6477f9ba6eeac5a633a2f",
            "47e8349d2a384f9c964c830226e4c3fd",
            "ecb25c907b444387ab5626092ce6a12f",
            "1069e6fc1b0c4626926cfdb27dbc597a",
            "6f74f071d3d841709b48efe7d1842b07",
            "c7a1f0f889df45138a64e647f37d1558",
            "e828b8ebb1cd4416b8fb81c6fc0aec19",
            "4e2b368e64304e6fa69fa093682d151e",
            "efb3d70abd75491a9104373a6651a678",
            "403208fa4a2f49d48bb717184a560a3d",
            "f75b2620a51042e7917fcdd325f84588",
            "e9db1e69b5ae4c179d7e46848c65703d",
            "9f8794faf02a47ceba924769bdd4c556",
            "092abab84d844a82b163ad06626c4a9b",
            "83cd5eedab8b44e3adbcb7ae11ec10f2",
            "ba2c453d26ba4b098a740466cbaa652a",
            "819a61d8e23442f38ba3e13471c2cc53",
            "6c93b984e92b4382a9abe412c5bf504b",
            "9277deb1a66540ee8475e0f728eac2a0",
            "4c3c5011ca8b4694a49dfa2488eff746",
            "8c3fa7cab0c541679fe6b889ddf53818",
            "ed434f88b2c9478daa137776d0f0b7d8",
            "6e84d37290dd4a78afc8d094e48ebefb",
            "25d77f65bc7741f5b51be81fe71b4e2c",
            "eab5113af43b4125b2b4f25088e336e3",
            "0093b37ea08f45c5a3a9c500d7e9cd7b"
          ]
        },
        "id": "IarZ3gdY8vbw",
        "outputId": "1d048394-f424-443f-bfa3-2a57d85080e6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['LY', 'MA', 'TN', 'DZ']\n",
            "TN    11738\n",
            "MA    11683\n",
            "LY    11649\n",
            "DZ    11629\n",
            "Name: dialect, dtype: int64\n",
            "{'LY': 0, 'MA': 1, 'TN': 2, 'DZ': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/376 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b6eb5ebcc34414babd2c8905c735f37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f74f071d3d841709b48efe7d1842b07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba2c453d26ba4b098a740466cbaa652a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define training arguments\n",
        "training_args = TrainingArguments(\"./train\")\n",
        "training_args.lr_scheduler_type = 'cosine'\n",
        "training_args.evaluate_during_training = True\n",
        "training_args.adam_epsilon =1e-8 \n",
        "training_args.learning_rate = 2e-05\n",
        "training_args.fp16 = True\n",
        "training_args.per_device_train_batch_size = 64\n",
        "training_args.per_device_eval_batch_size = 32\n",
        "training_args.gradient_accumulation_steps = 2\n",
        "training_args.num_train_epochs= 4\n",
        "training_args.warmup_steps = 0 \n",
        "training_args.evaluation_strategy = EvaluationStrategy.EPOCH\n",
        "training_args.seed = 42 \n",
        "training_args.disable_tqdm = False"
      ],
      "metadata": {
        "id": "Upc_cCGIAZQp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args.dataloader_pin_memory = False\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "set_seed(Rand_Seed) \n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset= evaluation_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "print(training_args.seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTHgtQpwAbqS",
        "outputId": "b749b026-efe5-4dc6-c494-927880d0e14a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "93rCEFRyAdlh",
        "outputId": "ec89a04f-232b-42eb-9f66-0798a005115d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1460' max='1460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1460/1460 15:44, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Macro F1 Pos Neg</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.191251</td>\n",
              "      <td>0.935862</td>\n",
              "      <td>0.976888</td>\n",
              "      <td>0.937208</td>\n",
              "      <td>0.935260</td>\n",
              "      <td>0.935445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.234800</td>\n",
              "      <td>0.184794</td>\n",
              "      <td>0.941244</td>\n",
              "      <td>0.978899</td>\n",
              "      <td>0.942521</td>\n",
              "      <td>0.940943</td>\n",
              "      <td>0.941148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.090800</td>\n",
              "      <td>0.213003</td>\n",
              "      <td>0.942808</td>\n",
              "      <td>0.975991</td>\n",
              "      <td>0.942952</td>\n",
              "      <td>0.942721</td>\n",
              "      <td>0.942847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.090800</td>\n",
              "      <td>0.238344</td>\n",
              "      <td>0.942211</td>\n",
              "      <td>0.975999</td>\n",
              "      <td>0.942351</td>\n",
              "      <td>0.942124</td>\n",
              "      <td>0.942240</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91      2072\n",
            "           1       1.00      0.97      0.98      2088\n",
            "           2       0.99      0.95      0.97      2039\n",
            "           3       0.89      0.88      0.88      2042\n",
            "\n",
            "    accuracy                           0.94      8241\n",
            "   macro avg       0.94      0.94      0.94      8241\n",
            "weighted avg       0.94      0.94      0.94      8241\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91      2072\n",
            "           1       1.00      0.97      0.99      2088\n",
            "           2       0.98      0.97      0.97      2039\n",
            "           3       0.91      0.88      0.89      2042\n",
            "\n",
            "    accuracy                           0.94      8241\n",
            "   macro avg       0.94      0.94      0.94      8241\n",
            "weighted avg       0.94      0.94      0.94      8241\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92      2072\n",
            "           1       0.99      0.98      0.98      2088\n",
            "           2       0.97      0.97      0.97      2039\n",
            "           3       0.90      0.90      0.90      2042\n",
            "\n",
            "    accuracy                           0.94      8241\n",
            "   macro avg       0.94      0.94      0.94      8241\n",
            "weighted avg       0.94      0.94      0.94      8241\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.92      0.92      2072\n",
            "           1       0.99      0.98      0.98      2088\n",
            "           2       0.97      0.97      0.97      2039\n",
            "           3       0.90      0.90      0.90      2042\n",
            "\n",
            "    accuracy                           0.94      8241\n",
            "   macro avg       0.94      0.94      0.94      8241\n",
            "weighted avg       0.94      0.94      0.94      8241\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1460, training_loss=0.12420918190315978, metrics={'train_runtime': 949.4421, 'train_samples_per_second': 196.743, 'train_steps_per_second': 1.538, 'total_flos': 9023444676422592.0, 'train_loss': 0.12420918190315978, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate test set\n",
        "test_results = trainer.predict(test_dataset)\n",
        "\n",
        "# Print test set results\n",
        "print(test_results.metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "O7zAsHLOAfWx",
        "outputId": "183de20d-d7da-479b-c40b-96f78a61163a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.92      0.92      2438\n",
            "           1       0.99      0.98      0.99      2388\n",
            "           2       0.97      0.96      0.97      2382\n",
            "           3       0.91      0.91      0.91      2488\n",
            "\n",
            "    accuracy                           0.94      9696\n",
            "   macro avg       0.94      0.94      0.94      9696\n",
            "weighted avg       0.94      0.94      0.94      9696\n",
            "\n",
            "{'test_loss': 0.23749323189258575, 'test_macro_f1': 0.944371009814825, 'test_macro_f1_pos_neg': 0.9759032322498589, 'test_macro_precision': 0.9446503610591757, 'test_macro_recall': 0.9441439047732056, 'test_accuracy': 0.9436881188118812, 'test_runtime': 16.5449, 'test_samples_per_second': 586.042, 'test_steps_per_second': 18.314}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model to a file\n",
        "torch.save(trainer.model.state_dict(), \"trainer.pth\")"
      ],
      "metadata": {
        "id": "fwaPTJPASBIY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(Model_Used, num_labels=4).to(device)\n",
        "\n",
        "# Load the trained model from disk\n",
        "model_state_dict = torch.load('/content/trainer.pth')\n",
        "model.load_state_dict(model_state_dict)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(Model_Used)\n",
        "\n",
        "\n",
        "\n",
        "# Tokenize the input sentence\n",
        "input_sentence = \"نبي نروح للحوش \"\n",
        "#input_sentence = 'واش دير للعشى'\n",
        "#input_sentence  = \"شوكران علا هاد \"\n",
        "#input_sentence = \"فرحان و نتشرف الي انا من اقلية الشعب الي عمري ما صدقت كذبة الثورة و الديمقراطية و ما عداها عليا حتى سياسي ملي حكمو من 2011 و ما تحكموش في تفكيري باجات فيسبوك و اعلاميين مرتزقة و سبر اراء غالط\"\n",
        "tokenized_input = tokenizer(input_sentence, padding=True, truncation=True, max_length=Max_Len, return_tensors='pt')\n",
        "input_ids = tokenized_input['input_ids'].to(device)\n",
        "attention_mask = tokenized_input['attention_mask'].to(device)\n",
        "\n",
        "# Pass the input tensor through the model to obtain the predictions\n",
        "outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
        "confidence_score = torch.softmax(outputs.logits, dim=1)[0][predicted_labels]\n",
        "\n",
        "# Print the predicted class and its corresponding label\n",
        "#{'LY': 0, 'MA': 1, 'TN': 2, 'DZ': 3}\n",
        "label_map = {0: \"LY\", 1: \"MA\", 2: \"TN\", 3: \"DZ\"}\n",
        "predicted_class = label_map[predicted_labels.item()]\n",
        "print(\"Predicted class:\", predicted_class)\n",
        "print(\"Confidence score:\", confidence_score.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jouGQc3SSACS",
        "outputId": "a4dad055-7544-4b1f-8d8d-f4440848d601"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: LY\n",
            "Confidence score: 0.997211754322052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XIs1aYAiPRbt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}