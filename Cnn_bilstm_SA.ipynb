{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEj8HzR9fl7YnMVfJJ/Jin",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Skander28/Models/blob/main/Cnn_bilstm_SA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaQmAYWs1wAv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7wOY4ro7va_",
        "outputId": "156872e7-f9c4-42eb-9c56-420e737cb1e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyEdq6kX7yDx",
        "outputId": "7df3de28-cc32-4c9c-ba8f-f1970833c9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Classroom\t    dialect_dataset.csv   preprocessed_tweets.csv\n",
            "'Colab Notebooks'   messages.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "filtered_df = pd.read_csv('/content/drive/MyDrive/preprocessed_tweets.csv')\n",
        "filtered_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uU0Oz6bT70Hn",
        "outputId": "f836528f-0d0d-4369-b832-d701a28beb67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                   id  dialect  \\\n",
              "0       15497  1009754958479151232        1   \n",
              "1       15498  1009794751548313600        1   \n",
              "2       15499  1019989115490787200        1   \n",
              "3       15500  1035479791758135168        1   \n",
              "4       15501  1035481122921164800        1   \n",
              "\n",
              "                                              tweets  \n",
              "0  قليلين ادب ومنافقين اختهم او قريبتهم تعاكس تقو...  \n",
              "1  اليبين متقلبين بالنسبه ليا انا ميليشياوي زمان ...  \n",
              "2  تانيه شاب ليبي بيرتاح لبنت مختلفه ويلاحظ انها ...  \n",
              "3  رانيا عقليتك متخلفه اولا الانسان يلي يحتاج اهل...  \n",
              "4  شكلك متعقده علشان الراجل تحبيه ازوج بنت يتيمه ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c2528e9-3bbe-48df-8b29-261300f1bb38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>dialect</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15497</td>\n",
              "      <td>1009754958479151232</td>\n",
              "      <td>1</td>\n",
              "      <td>قليلين ادب ومنافقين اختهم او قريبتهم تعاكس تقو...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15498</td>\n",
              "      <td>1009794751548313600</td>\n",
              "      <td>1</td>\n",
              "      <td>اليبين متقلبين بالنسبه ليا انا ميليشياوي زمان ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15499</td>\n",
              "      <td>1019989115490787200</td>\n",
              "      <td>1</td>\n",
              "      <td>تانيه شاب ليبي بيرتاح لبنت مختلفه ويلاحظ انها ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15500</td>\n",
              "      <td>1035479791758135168</td>\n",
              "      <td>1</td>\n",
              "      <td>رانيا عقليتك متخلفه اولا الانسان يلي يحتاج اهل...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15501</td>\n",
              "      <td>1035481122921164800</td>\n",
              "      <td>1</td>\n",
              "      <td>شكلك متعقده علشان الراجل تحبيه ازوج بنت يتيمه ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c2528e9-3bbe-48df-8b29-261300f1bb38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c2528e9-3bbe-48df-8b29-261300f1bb38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c2528e9-3bbe-48df-8b29-261300f1bb38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = filtered_df.dropna()"
      ],
      "metadata": {
        "id": "z-COZLxE9bch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "features = filtered_df.tweets.values\n",
        "labels = pd.get_dummies(filtered_df['dialect']).values"
      ],
      "metadata": {
        "id": "oHjhhJe02RHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 20000\n",
        "max_length= 200\n",
        "tokenizer = Tokenizer(num_words=vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=False)\n",
        "tokenizer.fit_on_texts(features)\n",
        "X = tokenizer.texts_to_sequences(features)"
      ],
      "metadata": {
        "id": "cjTuEsm22TBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from collections import Counter\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# use the stopwords\n",
        "stop_words = set(stopwords.words('arabic'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n7cvg2R-m3y",
        "outputId": "9e921b6c-88db-4559-a282-53114632a8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = []\n",
        "for tokens in X:\n",
        "    all_words.extend(tokens)\n",
        "\n",
        "stop_words = set(stopwords.words('arabic'))\n",
        "all_words = [word for word in all_words if word not in stop_words]\n",
        "\n",
        "word_counts = Counter(all_words)\n",
        "most_common_words = [word for word, count in word_counts.most_common(500)]\n",
        "\n",
        "def remove_common_words(tokens):\n",
        "  new_tokens = [token for token in tokens if token not in most_common_words]\n",
        "  return new_tokens\n",
        "\n",
        "X = remove_common_words(X)\n",
        "\n",
        "\n",
        "X = pad_sequences(X, maxlen=max_length)"
      ],
      "metadata": {
        "id": "STO_xtVt3O9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.1, random_state=42, shuffle=True)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "__QvQKel3PWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "rus=RandomUnderSampler(random_state=42)\n",
        "X_res, y_res = rus.fit_resample(X_train,y_train)"
      ],
      "metadata": {
        "id": "MfNDVs5p3SAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_res_, y_res_ = torch.tensor(X_res), torch.tensor(y_res)\n",
        "X_val, y_val = torch.tensor(X_val), torch.tensor(y_val)\n",
        "X_test, y_test = torch.tensor(X_test), torch.tensor(y_test)"
      ],
      "metadata": {
        "id": "Uwjl3zya3U76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DialectDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "9vqusbmC3dF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders for training, validation, and test sets\n",
        "train_dataset = DialectDataset(X_res, y_res)\n",
        "val_dataset = DialectDataset(X_val, y_val)\n",
        "test_dataset = DialectDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "d_Z3U-h_3gdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "Zp_pdmFd3mvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "vocab_size = 20000\n",
        "embedding_dim = 100\n",
        "hidden_dim = 128\n",
        "output_dim = 4\n",
        "num_layers = 2\n",
        "bidirectional = True\n",
        "lr = 0.01\n",
        "batch_size = 64\n",
        "num_epochs = 100\n",
        "patience = 5\n",
        "\n",
        "class BiLSTMAttention(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(BiLSTMAttention, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, embedding_dim), padding=(1, 0))\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 1), padding=(1, 0))\n",
        "        self.lstm = nn.LSTM(200, hidden_dim, num_layers=num_layers, bidirectional=True, dropout=0.5, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.attention = SelfAttention(hidden_dim * 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        conv1_out = F.relu(self.conv1(embedded.unsqueeze(1)))\n",
        "        conv2_out = F.relu(self.conv2(conv1_out))\n",
        "        conv2_out = conv2_out.permute(0, 2, 1, 3)\n",
        "        conv2_out = conv2_out.reshape(conv2_out.size(0), conv2_out.size(1), -1)\n",
        "        lstm_in = conv2_out.permute(0, 2, 1)\n",
        "        lstm_out, _ = self.lstm(lstm_in)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        attention_out , attention_weights= self.attention(lstm_out)\n",
        "        fc_out = self.fc(attention_out)\n",
        "        return fc_out, attention_weights\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "        )\n",
        "        \n",
        "    def forward(self, encoder_outputs):\n",
        "        energy = self.projection(encoder_outputs)\n",
        "        weights = F.softmax(energy.flatten(start_dim=1), dim=1)\n",
        "        outputs = (encoder_outputs * weights.unsqueeze(-1)).sum(dim=1)\n",
        "        return outputs, weights"
      ],
      "metadata": {
        "id": "VEIxcRNd3rfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BiLSTMAttention(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers).to(device)\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.01)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "counter_nb = 0\n",
        "for epoch in tqdm(range(24)):\n",
        "     model.train()\n",
        "     counter_nb = counter_nb + 1 \n",
        "     print(counter_nb)\n",
        "     running_loss = 0.0\n",
        "     with torch.cuda.device(0):\n",
        "       for batch in train_dataloader:\n",
        "         inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "         optimizer.zero_grad()\n",
        "         labels = labels.float()\n",
        "         outputs, _ = model(inputs)\n",
        "         loss = criterion(outputs, labels)\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "         running_loss += loss.item()\n",
        "         preds = torch.sigmoid(outputs) > 0.5\n",
        "         acc = accuracy_score(labels.cpu().detach().numpy(), preds.cpu().detach().numpy())\n",
        "         #print('Train Accuracy: {:.4f}'.format(acc))\n",
        "     epoch_loss = running_loss / (len(train_dataloader))\n",
        "\n",
        "     best_val_loss = np.inf\n",
        "     patience = 3\n",
        "     counter = 0\n",
        "     val_loss = 0.0\n",
        "     model.eval()\n",
        "     with torch.no_grad():\n",
        "         for batch in val_dataloader:\n",
        "             inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "             labels = labels.float()\n",
        "             outputs, _= model(inputs)\n",
        "             loss = criterion(outputs, labels)\n",
        "             val_loss += loss.item()\n",
        "             val_preds = torch.sigmoid(outputs) > 0.5\n",
        "             val_acc = accuracy_score(labels.cpu().detach().numpy(), val_preds.cpu().detach().numpy())\n",
        "             #print('Val Accuracy: {:.4f}'.format(val_acc))\n",
        "     val_loss = val_loss / (len(val_dataloader))\n",
        "     # Check if the validation loss has improved\n",
        "     if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                counter = 0\n",
        "     else:\n",
        "         counter += 1\n",
        "\n",
        "     # Stop the training process if the validation loss hasn't improved for `patience` epochs\n",
        "     if counter >= patience:\n",
        "         break\n",
        "     print(\" epoch loss :\", epoch_loss , \"| val loss :\", val_loss)\n",
        "     print('Train Accuracy: {:.4f}'.format(acc))\n",
        "     print('Val Accuracy: {:.4f}'.format(val_acc))\n",
        "\n",
        "print(\"Training stopped after epoch\", epoch)\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE9Y_aBf3sDm",
        "outputId": "7ac548b5-9c78-41f3-9e7a-f0e4814b8179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/24 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 1/24 [00:17<06:39, 17.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.515369971400948 | val loss : 0.4149530813671075\n",
            "Train Accuracy: 0.5227\n",
            "Val Accuracy: 0.5294\n",
            "2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 2/24 [00:34<06:16, 17.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.3564155053707861 | val loss : 0.35740098643761414\n",
            "Train Accuracy: 0.3864\n",
            "Val Accuracy: 0.7059\n",
            "3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 3/24 [00:51<05:57, 17.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.25531341308547606 | val loss : 0.37322803701345736\n",
            "Train Accuracy: 0.5455\n",
            "Val Accuracy: 0.7647\n",
            "4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 4/24 [01:08<05:39, 16.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.2006811195003089 | val loss : 0.39260648019038713\n",
            "Train Accuracy: 0.7955\n",
            "Val Accuracy: 0.7059\n",
            "5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 5/24 [01:25<05:22, 16.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.16186956561380816 | val loss : 0.42548883391114384\n",
            "Train Accuracy: 0.7500\n",
            "Val Accuracy: 0.7059\n",
            "6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 6/24 [01:42<05:08, 17.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.139983744662936 | val loss : 0.5060390244023159\n",
            "Train Accuracy: 0.8864\n",
            "Val Accuracy: 0.8235\n",
            "7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 7/24 [01:59<04:49, 17.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.12816055498776896 | val loss : 0.5176862257604415\n",
            "Train Accuracy: 0.7500\n",
            "Val Accuracy: 0.7059\n",
            "8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 8/24 [02:16<04:31, 17.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.11987137677929094 | val loss : 0.5153284903902274\n",
            "Train Accuracy: 0.7727\n",
            "Val Accuracy: 0.7647\n",
            "9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 9/24 [02:33<04:14, 16.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.10762341064551184 | val loss : 0.5503022604836867\n",
            "Train Accuracy: 0.8636\n",
            "Val Accuracy: 0.8235\n",
            "10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 10/24 [02:50<03:57, 16.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.10272873029593499 | val loss : 0.5790839106417619\n",
            "Train Accuracy: 0.8864\n",
            "Val Accuracy: 0.8824\n",
            "11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 11/24 [03:07<03:40, 17.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.09826089487841694 | val loss : 0.6539119290044675\n",
            "Train Accuracy: 0.8409\n",
            "Val Accuracy: 0.7059\n",
            "12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 12/24 [03:24<03:23, 16.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.09873875370349294 | val loss : 0.6149194753513887\n",
            "Train Accuracy: 0.8182\n",
            "Val Accuracy: 0.8235\n",
            "13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 13/24 [03:41<03:06, 16.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.09771684800745338 | val loss : 0.6875473424219168\n",
            "Train Accuracy: 0.9773\n",
            "Val Accuracy: 0.7059\n",
            "14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 14/24 [03:57<02:49, 16.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.09242181673005063 | val loss : 0.6878022858156607\n",
            "Train Accuracy: 0.9318\n",
            "Val Accuracy: 0.7647\n",
            "15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 15/24 [04:14<02:32, 16.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.09091542640761022 | val loss : 0.7323735917990024\n",
            "Train Accuracy: 0.8182\n",
            "Val Accuracy: 0.7647\n",
            "16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 16/24 [04:31<02:15, 16.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.09282138938865354 | val loss : 0.6830691821300067\n",
            "Train Accuracy: 0.8864\n",
            "Val Accuracy: 0.7059\n",
            "17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 17/24 [04:48<01:58, 16.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.08521560213818986 | val loss : 0.6920560432168154\n",
            "Train Accuracy: 0.8409\n",
            "Val Accuracy: 0.7647\n",
            "18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 18/24 [05:05<01:41, 16.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.0826081656019694 | val loss : 0.7064055473758624\n",
            "Train Accuracy: 0.8409\n",
            "Val Accuracy: 0.8235\n",
            "19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 19/24 [05:22<01:24, 16.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.08206686609454693 | val loss : 0.7299069896913492\n",
            "Train Accuracy: 0.9091\n",
            "Val Accuracy: 0.8235\n",
            "20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 20/24 [05:39<01:07, 16.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.07889523266023525 | val loss : 0.7670764461732827\n",
            "Train Accuracy: 0.8182\n",
            "Val Accuracy: 0.8235\n",
            "21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 21/24 [05:56<00:50, 16.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.08128538438950175 | val loss : 0.7457446983227363\n",
            "Train Accuracy: 0.9318\n",
            "Val Accuracy: 0.8824\n",
            "22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 22/24 [06:13<00:33, 16.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.08450504604286405 | val loss : 0.7288854924532083\n",
            "Train Accuracy: 0.8409\n",
            "Val Accuracy: 0.7647\n",
            "23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 23/24 [06:30<00:16, 16.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.08543788136974458 | val loss : 0.8208388491318777\n",
            "Train Accuracy: 0.9318\n",
            "Val Accuracy: 0.7647\n",
            "24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [06:47<00:00, 16.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch loss : 0.08103359503451214 | val loss : 0.7549706095686326\n",
            "Train Accuracy: 0.9091\n",
            "Val Accuracy: 0.8235\n",
            "Training stopped after epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "        labels = labels.float()\n",
        "        outputs, _ = model(inputs)\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        y_true.extend(labels.cpu().detach().numpy())\n",
        "        y_pred.extend(preds.cpu().detach().numpy())\n",
        "test_acc = accuracy_score(y_true, y_pred)\n",
        "test_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "print('Test Accuracy: {:.4f}'.format(test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Iogvg4NHukE",
        "outputId": "0647f5fc-17f4-4a47-a0e9-9dd0ebcf427d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model2.pth')"
      ],
      "metadata": {
        "id": "blA9EW05Ct5K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}